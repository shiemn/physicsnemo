# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
# SPDX-FileCopyrightText: All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

hydra:
    job:
          chdir: false
          name: norway_diffusion
    run:
          dir: ./output/${hydra:job.name}
    searchpath:
          - pkg://conf/base # Do not modify

# Base parameters for dataset, model, training, and validation
defaults:

    - dataset: custom 
    # The dataset type for training.
    # Accepted values:
    #   `gefs_hrrr`: full GEFS-HRRR dataset for continental US.
    #   `hrrr_mini`: smaller HRRR dataset (continental US), for fast experiments.
    #   `cwb`: full CWB dataset for Taiwan.
    #   `custom`: user-defined dataset. Parameters need to be specified below.

    - model: diffusion
    # The model type.
    # Accepted values:
    #     `regression`: a regression UNet for deterministic predictions
    #     `lt_aware_ce_regression`: similar to `regression` but with lead time
    #       conditioning
    #     `diffusion`: a diffusion UNet for residual predictions
    #     `patched_diffusion`: a more memory-efficient diffusion model
    #     `lt_aware_patched_diffusion`: similar to `patched_diffusion` but
    #       with lead time conditioning

    - model_size: mini
    # The model size configuration.
    # Accepted values:
    #     `normal`: normal model size
    #     `mini`: smaller model size for fast experiments

    - training: ${model}
    # The base training parameters. Determined by the model type.


# Dataset parameters. Used for `custom` dataset type.
# Modify or add below parameters that should be passed as argument to the
# user-defined dataset class.
dataset:
    type: norway #datasets/norway.py::NorwayDatasetH5
    data_path: /data/Norway/HCLIM3/preprocessed/NorCP_AROME_EC-EARTH
    stats_path: /data/Norway/HCLIM3/preprocessed/NorCP_AROME_EC-EARTH
    invariant_variables_path: /data/Norway/HCLIM3/
    
    # data_path: /Users/simon/Datasets/Norway/HCLIM3/preprocessed/NorCP_AROME_EC-EARTH
    # stats_path: /Users/simon/Datasets/Norway/HCLIM3/preprocessed/NorCP_AROME_EC-EARTH
    # invariant_variables_path: /Users/simon/Datasets/Norway/
    
    # Path to json stats file
    output_variables: ['precipitation']
    input_variables: ["hus500","hus850","ua500","ua850","va500","va850","ta500","ta850"]
    invariant_variables: ["elevation"]

# Training parameters
training:
    hp:
        training_duration: 8000000
        total_batch_size: 48
        # Training duration based on the number of processed samples
    io:
        print_progress_freq: 10000
        regression_checkpoint_path: /checkpoints/norway/checkpoints_regression/UNet.0.2000024.mdlus
        # Path to load the regression checkpoint
        checkpoint_dir: /checkpoints/norway
        save_n_recent_checkpoints: 5
        # Set to a positive integer to only keep the most recent n checkpoints

# Parameters for wandb logging
wandb:
    mode: online
    # Configure whether to use wandb: "offline", "online", "disabled"
    results_dir: "./wandb"
    # Directory to store wandb results
    watch_model: false
    # If true, wandb will track model parameters and gradients
